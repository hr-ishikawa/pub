{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed084ee8-50a8-4b00-af81-43a2c252fabf",
   "metadata": {},
   "source": [
    "## Cohere LLM (Command) APIの利用\n",
    "\n",
    "refer: https://docs.cohere.com/reference/chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc96a146-5872-40c0-8ba7-e6a7117a7148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-13 11:43:54\n",
      "3.13.9 (tags/v3.13.9:8183fa5, Oct 14 2025, 14:09:13) [MSC v.1944 64 bit (AMD64)]\n",
      "cohere = 5.20.2\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import sys\n",
    "import cohere\n",
    "from importlib.metadata import version\n",
    "\n",
    "print(datetime.now().strftime('%F %X'))\n",
    "print(sys.version)\n",
    "print('cohere =', version('cohere'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20557a80-3e93-49ed-bf50-d6684481a579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command-r7b-12-2024\n",
      "ChereのCommandモデルシリーズは、主に音声認識と自然言語処理に焦点を当てた音声アシスタントの技術を提供しています。ただし、Chereは2021年にCohere社に買収され、Cohereの製品の一部となりました。そのため、Cohereの製品ラインナップについて説明します。\n",
      "\n",
      "Cohereの製品ラインナップには、主に以下のようなモデルがあります。\n",
      "\n",
      "1. **Command (Large)**\n",
      "   - 特徴: 大規模な言語モデルで、高度な自然言語処理能力を備えています。\n",
      "   - 用途: 文章生成、質問応答、要約、翻訳、感情分析など。\n",
      "   - 特徴: 100億パラメータ以上、多言語対応、高度なコンテキスト理解能力。\n",
      "\n",
      "2. **Command (Medium)**\n",
      "   - 特徴: 中規模な言語モデルで、バランスの取れた性能を提供します。\n",
      "   - 用途: 文章生成、質問応答、要約、翻訳、感情分析など。\n",
      "   - 特徴: 10億パラメータ程度、多言語対応、コンテキスト理解能力。\n",
      "\n",
      "3. **Command (Small)**\n",
      "   - 特徴: 小規模な言語モデルで、効率的な性能を提供します。\n",
      "   - 用途: 文章生成、質問応答、要約、翻訳、感情分析など。\n",
      "   - 特徴: 1億パラメータ程度、多言語対応、コンテキスト理解能力。\n",
      "\n",
      "4. **Embeddings (Large)**\n",
      "   - 特徴: 大規模な埋め込みモデルで、テキストの意味をベクトル形式で表現します。\n",
      "   - 用途: テキスト分類、文書検索、感情分析、要約など。\n",
      "   - 特徴: 100億パラメータ以上、多言語対応、高度な意味理解能力。\n",
      "\n",
      "5. **Embeddings (Medium)**\n",
      "   - 特徴: 中規模な埋め込みモデルで、バランスの取れた性能を提供します。\n",
      "   - 用途: テキスト分類、文書検索、感情分析、要約など。\n",
      "   - 特徴: 10億パラメータ程度、多言語対応、意味理解能力。\n",
      "\n",
      "6. **Embeddings (Small)**\n",
      "   - 特徴: 小規模な埋め込みモデルで、効率的な性能を提供します。\n",
      "   - 用途: テキスト分類、文書検索、感情分析、要約など。\n",
      "   - 特徴: 1億パラメータ程度、多言語対応、意味理解能力。\n",
      "\n",
      "これらのモデルは、CohereのAPIを通じて利用でき、さまざまな用途に合わせて選択することができます。\n"
     ]
    }
   ],
   "source": [
    "# プロンプトを定義\n",
    "prompt = 'ChereのCommandモデルシリーズの各モデル毎の特徴を教えてください'\n",
    "\n",
    "# モデルを設定\n",
    "#COHERE_LLM_MODEL = 'command-a-03-2025'      # Commad A\n",
    "#COHERE_LLM_MODEL = 'command-r-plus-08-2024' # Commad R+\n",
    "#COHERE_LLM_MODEL = 'command-r-08-2024'      # Commad R\n",
    "COHERE_LLM_MODEL = 'command-r7b-12-2024'    # Commad R7b, 軽量\n",
    "print(COHERE_LLM_MODEL)\n",
    "\n",
    "# Cohereクライアントを作成\n",
    "COHERE_CLIENT = cohere.ClientV2(api_key=api_key)\n",
    "\n",
    "# モデルを使用してレスポンスを生成\n",
    "response = COHERE_CLIENT.chat(\n",
    "    model=COHERE_LLM_MODEL,\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'あなたは優秀な機械学習エンジニアです。質問に正確に答えてください。'},\n",
    "        {'role': 'user',   'content': prompt}\n",
    "    ],\n",
    "    temperature=0.2,  # 文書化の振れ幅 (Default: 0.3)\n",
    ")\n",
    "\n",
    "# 応答テキストの取得\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3ce54-b518-4f66-913a-fc337d182351",
   "metadata": {},
   "source": [
    "#### response内容\n",
    "```\n",
    "id='f4e0a15b-a1bb-43eb-9323-2f45bb5e724d' \n",
    "finish_reason='COMPLETE' \n",
    "message=AssistantMessageResponse(\n",
    "    role='assistant', \n",
    "    tool_calls=None, \n",
    "    tool_plan=None, \n",
    "    content=[\n",
    "        TextAssistantMessageResponseContentItem(\n",
    "            type='text', \n",
    "            text='ChereのCommandモデルシリーズは、...'\n",
    "        )\n",
    "    ], \n",
    "    citations=None\n",
    ") \n",
    "usage=Usage(\n",
    "    billed_units=UsageBilledUnits(\n",
    "        input_tokens=34.0, \n",
    "        output_tokens=611.0, \n",
    "        search_units=None, \n",
    "        classifications=None\n",
    "    ), \n",
    "    tokens=UsageTokens(\n",
    "        input_tokens=563.0, \n",
    "        output_tokens=613.0\n",
    "    ), \n",
    "    cached_tokens=512.0\n",
    ") \n",
    "logprobs=None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd981fa-8e7d-4ec1-8d06-1eec208fb41f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
