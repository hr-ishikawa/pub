{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f0250b-57b5-42e9-a9c6-d4962b61c21c",
   "metadata": {},
   "source": [
    "# Gemini + Chroma + Cohereで RAG を作ってみる\n",
    "\n",
    "**RAG**: embedding(Gemini) - similarity retrieval(Chroma) - re-ranking(Cohere)  \n",
    "\n",
    "Langchainを使わないで、なるべくプリミティブなAPIで\n",
    " - ennbedding(ベクトル化)/LLMは、Gemini ennbedding/LLMモデルを直接使用\n",
    " - ベクトルDBは、ChromaDB を直接使用\n",
    " - reranikgは、Cohere rerank を直接使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d21d94b5-8b2c-4ed4-b07d-432c9a51dda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genai=1.45.0, chroma=1.2.1, cohere=5.19.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.genai as genai\n",
    "import chromadb\n",
    "import cohere\n",
    "print(f\"genai={genai.__version__}, chroma={chromadb.__version__}, cohere={cohere.__version__}\")\n",
    "\n",
    "# ====== Gemini の設定 ======\n",
    "# Gemini API Keyを取得\n",
    "with open('GOOGLE_API_KEY.txt', 'r') as f:  # ファイルからAPI Keyを取得\n",
    "    api_key = f.read().strip()\n",
    "# Geminiモデルを指定\n",
    "llm_model       = 'gemini-2.0-flash'\n",
    "embedding_model = 'gemini-embedding-001'\n",
    "# Geminiクライアントの作成\n",
    "gemini_client = genai.Client(api_key=api_key)\n",
    "\n",
    "# ====== ChromaDB の設定 ======\n",
    "# clientの作成\n",
    "# 　メモリ上だけ (永続化しない), \n",
    "# 　永続化させる場合には、chromadb.PersistentClient(path='save_to')を使用)\n",
    "chroma_client = client = chromadb.EphemeralClient()\n",
    "\n",
    "# ====== Cohere の設定 ======\n",
    "# Cohereクライアントを作成\n",
    "with open('Cohere_API_KEY.txt', 'r') as f:  # ファイルからアクセスキーを取得\n",
    "    api_key = f.read().strip()\n",
    "co = cohere.ClientV2(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf9e827-38e9-40d3-99b7-6f223fb849d8",
   "metadata": {},
   "source": [
    "## まずは簡単なテキストで"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e2261-88f4-4152-99b3-b0436a5f4e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b449b91-6adb-4262-ae7d-73d9be097d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(embeddings)=9\n",
      " 0 embedding First 5 values: [0.0010123871, -0.027725141, 0.004763818, -0.085715435, -0.016764862]\n",
      " 1 embedding First 5 values: [-0.0032862844, -0.019554267, 0.006109047, -0.07946284, 0.008544021]\n",
      "Confirm: len(ids)=9, len(embeddings)=9, len(texts)=9\n",
      "collection count=9\n",
      "\n",
      "Q&A ----------------\n",
      "\n",
      "Q0: query=山田さんの職業は何ですか。,\n",
      "response=あら、山田さんですか。山田さんは果物屋さんですよ。前は八百屋さんだったみたいですね。甘いものがお好きなんだとか。意外とお酒は飲めないらしいですよ。\n",
      "\n",
      "retrieved doc 0: id=doc1, distances=0.4490359425544739, metadata=None\n",
      "          text=果物屋の山田です。以前は八百屋でした。甘いものが好きです。下戸です。\n",
      "retrieved doc 1: id=doc4, distances=0.732514500617981, metadata=None\n",
      "          text=サイクリングの好きな鈴木さんは自転車で会社へ通勤しています。高橋さんは会社の同僚です。\n",
      "retrieved doc 2: id=doc2, distances=0.743468165397644, metadata=None\n",
      "          text=佐藤さんは酒屋を営んでいました。現在はコンビニの店長です。泣き上戸です。\n",
      "\n",
      "Q1: query=佐藤さんの職業は何ですか。,\n",
      "response=あら、佐藤さんのことですか。佐藤さんはもともと酒屋さんをやってたみたいだけど、今はコンビニの店長さんなんですね！しかも、泣き上戸だって(笑)。お酒の席で会ったら、ちょっと面白い話が聞けそうですね！\n",
      "\n",
      "retrieved doc 0: id=doc2, distances=0.40844571590423584, metadata=None\n",
      "          text=佐藤さんは酒屋を営んでいました。現在はコンビニの店長です。泣き上戸です。\n",
      "retrieved doc 1: id=doc7, distances=0.5289136171340942, metadata=None\n",
      "          text=京都にお住いの小林さんは、佐藤さんのおいです。\n",
      "retrieved doc 2: id=doc3, distances=0.557520866394043, metadata=None\n",
      "          text=東京の渡辺さんと佐藤さんは、たまに居酒屋で一緒に飲んでいるようです。\n",
      "\n",
      "Q2: query=お酒を飲む人は誰ですか。,\n",
      "response=あら、お酒を飲む人ですか。ええと、渡辺さんと佐藤さんはたまに一緒に飲んでるみたいですね。中村さんも、高橋さんの上司として飲みに誘われることはあるみたいだけど、参加するかどうかは半々ってことですね。山田さんは甘いものが好きで下戸みたいだから、飲まないみたいね。\n",
      "retrieved doc 0: id=doc3, distances=0.6251603960990906, metadata=None\n",
      "          text=東京の渡辺さんと佐藤さんは、たまに居酒屋で一緒に飲んでいるようです。\n",
      "retrieved doc 1: id=doc1, distances=0.6808698773384094, metadata=None\n",
      "          text=果物屋の山田です。以前は八百屋でした。甘いものが好きです。下戸です。\n",
      "retrieved doc 2: id=doc6, distances=0.6953639984130859, metadata=None\n",
      "          text=中村さんは高橋さんの勤めている会社の上司です。よく飲みに誘われますが参加するかは半々です。\n",
      "\n",
      "Q3: query=関東に住んでいる人は誰ですか。,\n",
      "response=あら、それは面白い質問ね！えーっと、情報によると…\n",
      "\n",
      "*   **渡辺さん**：東京に住んでるから、関東の人ね！\n",
      "*   **佐藤さん**：渡辺さんと東京で飲んでるみたいだから、この人も関東の人で間違いないわ。\n",
      "*   **小林さん**：京都にお住まいだから、残念ながら関東の人じゃないわね。\n",
      "*   **加藤さん**：どこに住んでるか書いてないから、今回は分からなーい！\n",
      "\n",
      "だから、関東に住んでるのは**渡辺さんと佐藤さん**ってことになるわね！\n",
      "retrieved doc 0: id=doc3, distances=0.759975016117096, metadata=None\n",
      "          text=東京の渡辺さんと佐藤さんは、たまに居酒屋で一緒に飲んでいるようです。\n",
      "retrieved doc 1: id=doc7, distances=0.790023684501648, metadata=None\n",
      "          text=京都にお住いの小林さんは、佐藤さんのおいです。\n",
      "retrieved doc 2: id=doc8, distances=0.792526125907898, metadata=None\n",
      "          text=加藤さんは5人家族です。\n"
     ]
    }
   ],
   "source": [
    "# 検索対象テキスト ======================\n",
    "texts = [\n",
    "    '石川です。エンジニアです。散歩は嫌いではありません。', \n",
    "    '果物屋の山田です。以前は八百屋でした。甘いものが好きです。下戸です。',\n",
    "    '佐藤さんは酒屋を営んでいました。現在はコンビニの店長です。泣き上戸です。',\n",
    "    '東京の渡辺さんと佐藤さんは、たまに居酒屋で一緒に飲んでいるようです。',\n",
    "    'サイクリングの好きな鈴木さんは自転車で会社へ通勤しています。高橋さんは会社の同僚です。',\n",
    "    '伊藤さんと山本さんは、よく一緒に奥多摩へキャンプに行くようです',\n",
    "    '中村さんは高橋さんの勤めている会社の上司です。よく飲みに誘われますが参加するかは半々です。',\n",
    "    '京都にお住いの小林さんは、佐藤さんのおいです。',\n",
    "    '加藤さんは5人家族です。',\n",
    "]\n",
    "\n",
    "# テキストをエンベディング化(vector化)する  ======================\n",
    "# --- Embeddingの取得 ---\n",
    "response = gemini_client.models.embed_content(\n",
    "    model=embedding_model,\n",
    "    contents=texts\n",
    ")\n",
    "embeddings = [e.values for e in response.embeddings] # 配列へ変換\n",
    "\n",
    "print(f\"len(embeddings)={len(embeddings)}\") # 内容確認:\n",
    "for i, embedding in enumerate(embeddings[:2]):\n",
    "    print(f\"{i:2d} embedding First 5 values: {embedding[:5]}\")\n",
    "\n",
    "# ChromaDBの初期化、ローディング  ======================\n",
    "# DB内collectionの初期化(既存のcollectionがあったら削除)\n",
    "collection_name = 'novels'   # 任意の文字列\n",
    "try:\n",
    "    chroma_client.delete_collection(collection_name)\n",
    "except:\n",
    "    pass\n",
    "collection = chroma_client.create_collection(collection_name)\n",
    "\n",
    "# Document から必要な情報をまとめる\n",
    "ids = [f\"doc{i}\" for i in range(len(texts))] # id: ユニークな文字列\n",
    "\n",
    "# 確認\n",
    "print(f\"Confirm: len(ids)={len(ids)}, len(embeddings)={len(embeddings)}, len(texts)={len(texts)}\")\n",
    "\n",
    "# 一括で追加\n",
    "collection.add(\n",
    "    ids=ids,\n",
    "    embeddings=embeddings,\n",
    "    documents=texts,\n",
    "#    metadatas=metadatas        # (今回未使用、空辞書だとエラー)\n",
    ")\n",
    "print(f\"collection count={collection.count()}\")\n",
    "\n",
    "# LLMモデルを使用してレスポンスを生成\n",
    "queries = []\n",
    "queries.append('山田さんの職業は何ですか。')\n",
    "queries.append('佐藤さんの職業は何ですか。')\n",
    "queries.append('お酒を飲む人は誰ですか。')\n",
    "queries.append('関東に住んでいる人は誰ですか。')\n",
    "print(f\"\\nQ&A ----------------\")\n",
    "for q_no, query in enumerate(queries):\n",
    "\n",
    "    # query を embedding\n",
    "    embedded_query = gemini_client.models.embed_content(\n",
    "        model=embedding_model,\n",
    "        contents=query\n",
    "    )\n",
    "    query_vector  = embedded_query.embeddings[0].values\n",
    "\n",
    "    # embeddingでretrieve\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_vector ],\n",
    "        n_results=3\n",
    "    )\n",
    "    retreaved_texts = results['documents'][0]\n",
    "\n",
    "    # Reraning <<略>>\n",
    "\n",
    "    # retreaveされたtextsで、LLMを使ってqueryに回答\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model=llm_model,\n",
    "        contents=[f\"QUESTION{query}\", f\"CONTENTS\"] + retreaved_texts,\n",
    "        config=genai.types.GenerateContentConfig(\n",
    "            system_instruction=\"あなたは気さくな隣人です。質問に日常会話的に答えてください。\",\n",
    "            temperature=0.7,  # ★ creativity の度合いを調整\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 結果表示\n",
    "    print(f\"\\nQ{q_no}: query={query},\\nresponse={response.text}\")\n",
    "    for i in range(len(results['documents'][0])):     # [0]が必要なのは、複数のqueryを投げられるため\n",
    "        print(f\"retrieved doc {i}: id={results['ids'][0][i]}, \" +\n",
    "              f\"distances={results['distances'][0][i]}, metadata={results['metadatas'][0][i]}\" +\n",
    "              f\"\\n          text={results['documents'][0][i][:200]}\")   # 最初の200文字だけ表示\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3cbc25-2bfa-4f31-afe9-2f4924a96b09",
   "metadata": {},
   "source": [
    "## 大きなドキュメントの分割、メタデータ利用\n",
    "\n",
    "ドキュメントとして、青空文庫を利用させていただきました。\n",
    "\n",
    "一部Langchainを使用  \n",
    "以下の機能は単機能で、特にRecursiveCharacterTextSplitter()は代わりになるライブラリが見つからず、スクラッチで作成するのも結構大変ということで、使わせていただきます。\n",
    " - Documentクラス                    # テキスト+メタデータ  \n",
    " - DirectoryLoader()                 # ディレクトリ単位でファイルを取得、Document型へ  \n",
    " - RecursiveCharacterTextSplitter()  # Document型のテキストを指定サイズでChankへ分割  \n",
    "                                     # 区切文字列、ラップサイズを指定、メタデータを各Chankへコピー  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbecea8-0d99-40ad-9575-3142a2a4d3e5",
   "metadata": {},
   "source": [
    "### Vector Storeへの登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3cff2a6d-8abe-4a38-9084-28d4340571e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'novels\\\\1_kumono_ito.txt', 'filename': '1_kumono_ito.txt', 'genre': 'novel', 'title': '蜘蛛の糸', 'author': '芥川竜之介', 'year': '1918'}\n",
      "0: 蜘蛛の糸, n_chunks: 1\n",
      "collection count=1\n",
      "1: 注文の多い料理店, n_chunks: 1\n",
      "collection count=2\n",
      "2: 銀河鉄道の夜, n_chunks: 6\n",
      "collection count=8\n",
      "3: 風の又三郎, n_chunks: 4\n",
      "collection count=12\n",
      "4: セロ弾きのゴーシュ, n_chunks: 2\n",
      "collection count=14\n",
      "5: 坊ちゃん, n_chunks: 11\n",
      "collection count=25\n",
      "6: 怪人二十面相, n_chunks: 12\n",
      "collection count=37\n",
      "7: 山椒大夫, n_chunks: 3\n",
      "collection count=40\n",
      "8: , n_chunks: 10\n",
      "collection count=50\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# テキストファイル・メタデータ\n",
    "matadata_dic = {\n",
    "    '1_kumono_ito.txt': {\n",
    "        'genre': 'novel', 'title':'蜘蛛の糸',          'author':'芥川竜之介', 'year':'1918'},\n",
    "    '2_chumonno_oi_ryoriten.txt': {\n",
    "        'genre': 'novel', 'title':'注文の多い料理店',  'author':'宮沢賢治',   'year':'1924'},\n",
    "    '2_kazeno_matasaburo.txt': {\n",
    "        'genre': 'novel', 'title':'風の又三郎',        'author':'宮沢賢治',   'year':'1934'},\n",
    "    '2_serohikino_goshu.txt': {\n",
    "        'genre': 'novel', 'title':'セロ弾きのゴーシュ', 'author':'宮沢賢治',   'year':'1934'},\n",
    "    '2_gingatetsudono_yoru.txt': {\n",
    "        'genre': 'novel', 'title':'銀河鉄道の夜',      'author':'宮沢賢治',   'year':'1934'},\n",
    "    '3_bocchan.txt': {\n",
    "        'genre': 'novel', 'title':'坊ちゃん',         'author':'夏目漱石',   'year':'1906'},\n",
    "    '4_kaijin_nijumenso.txt': {\n",
    "        'genre': 'novel', 'title':'怪人二十面相',      'author':'江戸川乱歩', 'year':'1936'},\n",
    "    '5_sanshodayu.txt': {\n",
    "        'genre': 'novel', 'title':'山椒大夫',         'author':'森鷗外',     'year':'1915'},\n",
    "}\n",
    "null_dic = {'genre':'','title':'', 'author':'','year':''}\n",
    "\n",
    "# 小説データをロード ======================\n",
    "novels_dir = './novels/'\n",
    "loader = DirectoryLoader(novels_dir, glob='*.txt') # ディレクトリ内の.txtを指定して\n",
    "documents = loader.load()   # ドキュメント(メタデータ(ファイル名)+テキスト)としてロード\n",
    "\n",
    "# 各ドキュメントにメタデータを付与 ======================\n",
    "for doc in documents:\n",
    "    fn = os.path.basename(doc.metadata['source'])\n",
    "    doc.metadata.update({'filename': fn} | matadata_dic.get(fn, null_dic))\n",
    "print(documents[0].metadata) # 確認\n",
    "\n",
    "# ChromaDBの初期化、ローディング  ======================\n",
    "# DB内collectionの初期化(既存のcollectionがあったら削除)\n",
    "collection_name = 'novels'   # 任意の文字列\n",
    "try:\n",
    "    chroma_client.delete_collection(collection_name)\n",
    "except:\n",
    "    pass\n",
    "collection = chroma_client.create_collection(collection_name)\n",
    "\n",
    "# ドキュメント毎に (embedding tokenサイズ制限により) ======================\n",
    "for doc_no, doc in enumerate(documents):\n",
    "    # ドキュメントをチャンクへ分割 ======================\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 10000,\n",
    "        chunk_overlap = 100,\n",
    "        separators = ['。', '\\n'] # 分割位置の指定\n",
    "    )\n",
    "    chunks = text_splitter.split_documents([doc])\n",
    "    print(f\"{doc_no}: {doc.metadata['title']}, n_chunks: {len(chunks)}\")                                            # 確認\n",
    "    #print(f\"\\nchunks[0] --------\\n{chunks[0].page_content[:100]},\\n{chunks[0].metadata}\")\n",
    "    \n",
    "    # chunk を embedding  ======================\n",
    "    embedded_chunks = gemini_client.models.embed_content(\n",
    "        model = embedding_model,\n",
    "        contents = [c.page_content for c in chunks]\n",
    "    )\n",
    "    chunk_vectors = [e.values for e in embedded_chunks.embeddings]\n",
    "        \n",
    "    # id生成\n",
    "    ids = [f\"doc{doc_no}-{i}\" for i in range(len(chunks))] # id: ユニークな文字列\n",
    "    # 一括で追加\n",
    "    collection.add(\n",
    "        ids = ids,\n",
    "        embeddings = chunk_vectors,\n",
    "        documents = [c.page_content for c in chunks],\n",
    "        metadatas = [m.metadata for m in chunks]\n",
    "    )\n",
    "    print(f\"collection count={collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e861195-d8aa-407b-ade8-2b3a69e78876",
   "metadata": {},
   "source": [
    "### Retreival, Re-ranking, LLM Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4d71e596-179b-40fe-ab18-f89777576fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q&A ----------------\n",
      "\n",
      "Q0: query=蜘蛛の糸は何に使われましたか ==============\n",
      "Retrieval (Chrom distances: 値が小さい方が近い) 結果:\n",
      "retrieved chunk 0: id=doc0-0, distance=0.59081, title=蜘蛛の糸\n",
      "retrieved chunk 1: id=doc6-4, distance=0.79448, title=怪人二十面相\n",
      "retrieved chunk 2: id=doc6-5, distance=0.80821, title=怪人二十面相\n",
      "retrieved chunk 3: id=doc2-4, distance=0.81376, title=銀河鉄道の夜\n",
      "retrieved chunk 4: id=doc6-3, distance=0.81417, title=怪人二十面相\n",
      "retrieved chunk 5: id=doc6-2, distance=0.81449, title=怪人二十面相\n",
      "retrieved chunk 6: id=doc6-9, distance=0.81793, title=怪人二十面相\n",
      "retrieved chunk 7: id=doc3-2, distance=0.82108, title=風の又三郎\n",
      "retrieved chunk 8: id=doc6-6, distance=0.82363, title=怪人二十面相\n",
      "retrieved chunk 9: id=doc2-2, distance=0.82711, title=銀河鉄道の夜\n",
      "Retrieval + Rerank (Cohere reranking score: 値が大きい方が近似) 結果:\n",
      "reranked chunk 0: id=doc0-0, score=0.70165, title=蜘蛛の糸\n",
      "reranked chunk 1: id=doc3-2, score=0.46643, title=風の又三郎\n",
      "reranked chunk 2: id=doc6-5, score=0.39754, title=怪人二十面相\n",
      "reranked chunk 3: id=doc6-6, score=0.26186, title=怪人二十面相\n",
      "reranked chunk 4: id=doc2-2, score=0.15461, title=銀河鉄道の夜\n",
      "\n",
      "Q0: query=蜘蛛の糸は何に使われましたか,\n",
      "response=蜘蛛の糸は、御釈迦様が地獄にいる罪人である犍陀多を救い出すために、極楽の蓮池に生えている蓮の葉の上の蜘蛛がかけた銀色の糸を使いました。御釈迦様はその糸を手に取り、地獄の底へまっすぐに下ろしました。\n",
      "\n",
      "Q1: query=ゴーシュの仕事は何ですか ==============\n",
      "Retrieval (Chrom distances: 値が小さい方が近い) 結果:\n",
      "retrieved chunk 0: id=doc4-0, distance=0.53098, title=セロ弾きのゴーシュ\n",
      "retrieved chunk 1: id=doc4-1, distance=0.59222, title=セロ弾きのゴーシュ\n",
      "retrieved chunk 2: id=doc5-7, distance=0.82920, title=坊ちゃん\n",
      "retrieved chunk 3: id=doc5-4, distance=0.83236, title=坊ちゃん\n",
      "retrieved chunk 4: id=doc2-2, distance=0.84472, title=銀河鉄道の夜\n",
      "retrieved chunk 5: id=doc5-9, distance=0.84617, title=坊ちゃん\n",
      "retrieved chunk 6: id=doc5-10, distance=0.85107, title=坊ちゃん\n",
      "retrieved chunk 7: id=doc5-3, distance=0.85508, title=坊ちゃん\n",
      "retrieved chunk 8: id=doc8-7, distance=0.86072, title=\n",
      "retrieved chunk 9: id=doc5-5, distance=0.86189, title=坊ちゃん\n",
      "Retrieval + Rerank (Cohere reranking score: 値が大きい方が近似) 結果:\n",
      "reranked chunk 0: id=doc4-0, score=0.81805, title=セロ弾きのゴーシュ\n",
      "reranked chunk 1: id=doc4-1, score=0.59118, title=セロ弾きのゴーシュ\n",
      "reranked chunk 2: id=doc2-2, score=0.16274, title=銀河鉄道の夜\n",
      "reranked chunk 3: id=doc5-9, score=0.10642, title=坊ちゃん\n",
      "reranked chunk 4: id=doc5-5, score=0.08848, title=坊ちゃん\n",
      "\n",
      "Q1: query=ゴーシュの仕事は何ですか,\n",
      "response=## ゴーシュの仕事について\n",
      "\n",
      "セロ弾きのゴーシュは、町の活動写真館でセロを弾く係です。\n",
      "\n",
      "Q2: query=坊ちゃんの姓名は何ですか ==============\n",
      "Retrieval (Chrom distances: 値が小さい方が近い) 結果:\n",
      "retrieved chunk 0: id=doc5-0, distance=0.63283, title=坊ちゃん\n",
      "retrieved chunk 1: id=doc6-2, distance=0.71389, title=怪人二十面相\n",
      "retrieved chunk 2: id=doc5-6, distance=0.72715, title=坊ちゃん\n",
      "retrieved chunk 3: id=doc5-4, distance=0.72729, title=坊ちゃん\n",
      "retrieved chunk 4: id=doc5-3, distance=0.73052, title=坊ちゃん\n",
      "retrieved chunk 5: id=doc5-9, distance=0.73480, title=坊ちゃん\n",
      "retrieved chunk 6: id=doc6-1, distance=0.73829, title=怪人二十面相\n",
      "retrieved chunk 7: id=doc3-0, distance=0.74062, title=風の又三郎\n",
      "retrieved chunk 8: id=doc3-1, distance=0.74318, title=風の又三郎\n",
      "retrieved chunk 9: id=doc7-2, distance=0.74752, title=山椒大夫\n",
      "Retrieval + Rerank (Cohere reranking score: 値が大きい方が近似) 結果:\n",
      "reranked chunk 0: id=doc5-0, score=0.54507, title=坊ちゃん\n",
      "reranked chunk 1: id=doc6-2, score=0.50710, title=怪人二十面相\n",
      "reranked chunk 2: id=doc5-9, score=0.31368, title=坊ちゃん\n",
      "reranked chunk 3: id=doc3-1, score=0.22723, title=風の又三郎\n",
      "reranked chunk 4: id=doc3-0, score=0.20468, title=風の又三郎\n",
      "\n",
      "Q2: query=坊ちゃんの姓名は何ですか,\n",
      "response=「坊っちゃん」という愛称で呼ばれる主人公には、作中で明確な姓名は記されていません。\n",
      "\n",
      "Q3: query=怪人の名前は何ですか ==============\n",
      "Retrieval (Chrom distances: 値が小さい方が近い) 結果:\n",
      "retrieved chunk 0: id=doc6-0, distance=0.75061, title=怪人二十面相\n",
      "retrieved chunk 1: id=doc3-0, distance=0.75125, title=風の又三郎\n",
      "retrieved chunk 2: id=doc6-3, distance=0.76237, title=怪人二十面相\n",
      "retrieved chunk 3: id=doc6-6, distance=0.76594, title=怪人二十面相\n",
      "retrieved chunk 4: id=doc6-5, distance=0.76707, title=怪人二十面相\n",
      "retrieved chunk 5: id=doc6-8, distance=0.77932, title=怪人二十面相\n",
      "retrieved chunk 6: id=doc6-10, distance=0.78462, title=怪人二十面相\n",
      "retrieved chunk 7: id=doc6-2, distance=0.79208, title=怪人二十面相\n",
      "retrieved chunk 8: id=doc6-4, distance=0.79276, title=怪人二十面相\n",
      "retrieved chunk 9: id=doc6-9, distance=0.79870, title=怪人二十面相\n",
      "Retrieval + Rerank (Cohere reranking score: 値が大きい方が近似) 結果:\n",
      "reranked chunk 0: id=doc3-0, score=0.66282, title=風の又三郎\n",
      "reranked chunk 1: id=doc6-6, score=0.61973, title=怪人二十面相\n",
      "reranked chunk 2: id=doc6-0, score=0.51764, title=怪人二十面相\n",
      "reranked chunk 3: id=doc6-10, score=0.43583, title=怪人二十面相\n",
      "reranked chunk 4: id=doc6-5, score=0.39726, title=怪人二十面相\n",
      "\n",
      "Q3: query=怪人の名前は何ですか,\n",
      "response=怪人の名前は風野又三郎です。\n",
      "\n",
      "\n",
      "Q4: query=二十面相が現れた場所をすべて挙げてください ==============\n",
      "Retrieval (Chrom distances: 値が小さい方が近い) 結果:\n",
      "retrieved chunk 0: id=doc6-0, distance=0.55571, title=怪人二十面相\n",
      "retrieved chunk 1: id=doc6-8, distance=0.59162, title=怪人二十面相\n",
      "retrieved chunk 2: id=doc6-3, distance=0.59325, title=怪人二十面相\n",
      "retrieved chunk 3: id=doc6-7, distance=0.61279, title=怪人二十面相\n",
      "retrieved chunk 4: id=doc6-10, distance=0.61440, title=怪人二十面相\n",
      "retrieved chunk 5: id=doc6-11, distance=0.61692, title=怪人二十面相\n",
      "retrieved chunk 6: id=doc6-4, distance=0.61798, title=怪人二十面相\n",
      "retrieved chunk 7: id=doc6-1, distance=0.61860, title=怪人二十面相\n",
      "retrieved chunk 8: id=doc6-6, distance=0.62505, title=怪人二十面相\n",
      "retrieved chunk 9: id=doc6-9, distance=0.64255, title=怪人二十面相\n",
      "Retrieval + Rerank (Cohere reranking score: 値が大きい方が近似) 結果:\n",
      "reranked chunk 0: id=doc6-11, score=0.75810, title=怪人二十面相\n",
      "reranked chunk 1: id=doc6-0, score=0.74808, title=怪人二十面相\n",
      "reranked chunk 2: id=doc6-10, score=0.72815, title=怪人二十面相\n",
      "reranked chunk 3: id=doc6-4, score=0.71137, title=怪人二十面相\n",
      "reranked chunk 4: id=doc6-6, score=0.70263, title=怪人二十面相\n",
      "\n",
      "Q4: query=二十面相が現れた場所をすべて挙げてください,\n",
      "response=怪盗二十面相が現れた場所は以下の通りです。\n",
      "\n",
      "1.  **羽柴壮太郎氏の邸宅：** ロマノフ王家の宝冠を飾ったダイヤモンドを盗むと予告状を送りつけ、羽柴壮一に化けて邸内に侵入しました。\n",
      "2.  **国立博物館：** 事前に予告状を送りつけ、博物館の美術品を盗み出しました。\n",
      "3.  **日下部老人の美術城：** 明智小五郎に化けて美術城に侵入し、美術品を盗み出しました。\n",
      "4.  **戸山ヶ原の廃屋：** 小林少年を誘拐し、アジトとして利用しました。\n",
      "5.  **東京駅の鉄道ホテル：** 外務省の辻野氏に化けて明智小五郎を出迎え、ホテルに誘い込みました。\n",
      "\n",
      "Q5: query=山椒大夫は最後にどうなりましたか ==============\n",
      "Retrieval (Chrom distances: 値が小さい方が近い) 結果:\n",
      "retrieved chunk 0: id=doc7-0, distance=0.59880, title=山椒大夫\n",
      "retrieved chunk 1: id=doc7-2, distance=0.61188, title=山椒大夫\n",
      "retrieved chunk 2: id=doc0-0, distance=0.72264, title=蜘蛛の糸\n",
      "retrieved chunk 3: id=doc7-1, distance=0.72453, title=山椒大夫\n",
      "retrieved chunk 4: id=doc5-8, distance=0.72555, title=坊ちゃん\n",
      "retrieved chunk 5: id=doc5-10, distance=0.74108, title=坊ちゃん\n",
      "retrieved chunk 6: id=doc5-9, distance=0.74394, title=坊ちゃん\n",
      "retrieved chunk 7: id=doc5-4, distance=0.75128, title=坊ちゃん\n",
      "retrieved chunk 8: id=doc1-0, distance=0.75431, title=注文の多い料理店\n",
      "retrieved chunk 9: id=doc5-2, distance=0.75951, title=坊ちゃん\n",
      "Retrieval + Rerank (Cohere reranking score: 値が大きい方が近似) 結果:\n",
      "reranked chunk 0: id=doc7-0, score=0.84277, title=山椒大夫\n",
      "reranked chunk 1: id=doc7-1, score=0.81025, title=山椒大夫\n",
      "reranked chunk 2: id=doc7-2, score=0.78769, title=山椒大夫\n",
      "reranked chunk 3: id=doc5-8, score=0.13340, title=坊ちゃん\n",
      "reranked chunk 4: id=doc5-2, score=0.10901, title=坊ちゃん\n",
      "\n",
      "Q5: query=山椒大夫は最後にどうなりましたか,\n",
      "response=山椒大夫の物語には、最後に山椒大夫がどうなったのかという直接的な記述はありません。しかし、物語の結末からは、彼が権力を失い、罪を償うことになったと推測できます。\n",
      "\n",
      "物語の終盤で、厨子王は丹後国の国守となり、最初の政として人身売買を禁じます。この措置により、山椒大夫は奴婢を解放せざるを得なくなり、経済的な基盤を失います。\n",
      "\n",
      "物語には直接的な記述はありませんが、これらの状況から、山椒大夫はこれまでの悪行が明らかになり、国守となった厨子王によって何らかの処罰を受け、没落したと推測できます。\n"
     ]
    }
   ],
   "source": [
    "# LLMモデルを使用してレスポンスを生成\n",
    "queries = []\n",
    "queries.append('蜘蛛の糸は何に使われましたか')\n",
    "queries.append('ゴーシュの仕事は何ですか')\n",
    "queries.append('坊ちゃんの姓名は何ですか')\n",
    "queries.append('怪人の名前は何ですか')\n",
    "queries.append('二十面相が現れた場所をすべて挙げてください')\n",
    "queries.append('山椒大夫は最後にどうなりましたか')\n",
    "\n",
    "print(f\"\\nQ&A ----------------\")\n",
    "top_k = 5\n",
    "for q_no, query in enumerate(queries):\n",
    "    print(f\"\\nQ{q_no}: query={query} ==============\")\n",
    "    \n",
    "    # Embed the query\n",
    "    embedded_query = gemini_client.models.embed_content(\n",
    "        model=embedding_model,\n",
    "        contents=query\n",
    "    )\n",
    "    query_vector = embedded_query.embeddings[0].values\n",
    "\n",
    "    # embeddingでretrieve\n",
    "    retreaved_results = collection.query(\n",
    "        query_embeddings = [query_vector ],\n",
    "        n_results = top_k*2\n",
    "    )\n",
    "    retreaved_texts = retreaved_results['documents'][0]\n",
    "    # 結果表示\n",
    "    print(f\"Retrieval (Chrom distances: 値が小さい方が近い) 結果:\")\n",
    "    for rank, doc in enumerate(retreaved_results['documents'][0]): # [0]が必要なのは、複数のqueryを投げられるため\n",
    "        print(f\"retrieved chunk {rank}: \" + \n",
    "              f\"id={retreaved_results['ids'][0][rank]}, \" +\n",
    "              f\"distance={retreaved_results['distances'][0][rank]:.5f}, \" +\n",
    "              f\"title={retreaved_results['metadatas'][0][rank]['title']}\")\n",
    "\n",
    "    # Rerank the documents\n",
    "    candidates = retreaved_results['documents'][0]\n",
    "    rerank_results = co.rerank(\n",
    "        model=\"rerank-v3.5\",\n",
    "        query=query,\n",
    "        documents=candidates,\n",
    "        top_n=top_k,\n",
    "    ).results\n",
    "    reranked_texts  = [candidates[r.index] for r in rerank_results]\n",
    "    # --- 結果表示 ---\n",
    "    print(f\"Retrieval + Rerank (Cohere reranking score: 値が大きい方が近似) 結果:\")\n",
    "    for rank, result in enumerate(rerank_results): # index: 元のDocumentリストへのindex\n",
    "        print(f\"reranked chunk {rank}: \" + \n",
    "              f\"id={retreaved_results['ids'][0][result.index]}, \" +\n",
    "              f\"score={result.relevance_score:.5f}, \" +\n",
    "              f\"title={retreaved_results['metadatas'][0][result.index]['title']}\")\n",
    "\n",
    "    # retreaveされたtextsで、LLMを使ってqueryに回答\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model=llm_model,\n",
    "        contents=[f\"QUESTION{query}\", f\"CONTENTS\"] + reranked_texts, # rerank結果を利用\n",
    "        config=genai.types.GenerateContentConfig(\n",
    "            system_instruction=\"あなたは文学者です。質問に誠実にに答えてください。\",\n",
    "            temperature=0.7,  # ★ creativity の度合いを調整\n",
    "        )\n",
    "    )\n",
    "    # 結果表示\n",
    "    print(f\"\\nQ{q_no}: query={query},\\nresponse={response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c317669f-4311-4421-ba37-5ddd47653112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee7b63-194b-4d81-8f4f-80aa7566105c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
