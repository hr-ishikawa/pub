{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f0250b-57b5-42e9-a9c6-d4962b61c21c",
   "metadata": {},
   "source": [
    "# Gemini + Chroma で RAG を作ってみる\n",
    "\n",
    "Langchainを使わないで、\n",
    " - ennbedding(ベクトル化)/LLMは、Gemini ennbedding/LLMモデルを直接使用\n",
    " - ベクトルDBは、ChromaDB を直接使用\n",
    "\n",
    "### RAG\n",
    "1. あらかじめ用意したテキスト(群)を数値化(ベクター化/embedding)し、ベクトルDBに保存\n",
    "2. テキストに対する質問文を数値化し、数値化されたベクトルDB中の各文書との距離(数値的差)を求め、距離の小さいものの上位を候補として抽出\n",
    "3. 抽出されたテキストを、質問文とともにLLMへ投げると、質問文に合わせてテキストを解釈し、回答"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf9e827-38e9-40d3-99b7-6f223fb849d8",
   "metadata": {},
   "source": [
    "## まずは簡単なテキストで\n",
    "\n",
    "Langchain利用に比べると、かなり面倒くさくなる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e5e2261-88f4-4152-99b3-b0436a5f4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.genai as genai\n",
    "import chromadb\n",
    "\n",
    "# ====== Gemini の設定 ======\n",
    "# Gemini API Keyを取得\n",
    "with open('GOOGLE_API_KEY.txt', 'r') as f:  # ファイルからAPI Keyを取得\n",
    "    api_key = f.read().strip()\n",
    "\n",
    "# Geminiモデルを指定\n",
    "llm_model       = 'gemini-2.0-flash-exp'\n",
    "embedding_model = 'gemini-embedding-001'\n",
    "\n",
    "# Geminiクライアントの作成\n",
    "gemini_client = genai.Client(api_key=api_key)\n",
    "# enbedding関数の定義\n",
    "def embed_texts(texts):\n",
    "    \"\"\"\n",
    "    複数の文字列をGemini Clientで埋め込みベクトルに変換する関数。\n",
    "        Args: texts (List[str]):\n",
    "                埋め込み対象の文字列リスト。\n",
    "        Returns: List[List[float]]:\n",
    "                各文字列に対応する数値ベクトル（埋め込み）のリスト。\n",
    "                    [\n",
    "                      [v11, v12, v13, ...],  # 1つ目の文字列のベクトル\n",
    "                      [v21, v22, v23, ...],  # 2つ目の文字列のベクトル\n",
    "                      ...\n",
    "                    ]\n",
    "    \"\"\"\n",
    "    response = gemini_client.models.embed_content(\n",
    "        model=embedding_model,\n",
    "        contents=texts\n",
    "    )\n",
    "    return [e.values for e in response.embeddings]\n",
    "\n",
    "# ====== ChromaDB の設定 ======\n",
    "# clientの作成\n",
    "# 　メモリ上だけ (永続化しない), \n",
    "# 　永続化させる場合には、chromadb.PersistentClient(path='save_to')を使用)\n",
    "chroma_client = client = chromadb.EphemeralClient()\n",
    "\n",
    "# DB内collectionの初期化(既存のcollectionがあったら削除)\n",
    "collection_name = 'novels'   # 任意の文字列\n",
    "try:\n",
    "    chroma_client.delete_collection(collection_name)\n",
    "except:\n",
    "    pass\n",
    "collection = chroma_client.create_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b449b91-6adb-4262-ae7d-73d9be097d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(embeddings)=9\n",
      " 0 embedding First 5 values: [0.0010123871, -0.027725141, 0.004763818, -0.085715435, -0.016764862]\n",
      " 1 embedding First 5 values: [-0.0032862844, -0.019554267, 0.006109047, -0.07946284, 0.008544021]\n",
      "Confirm: len(ids)=9, len(embeddings)=9, len(texts)=9\n",
      "collection count=9\n",
      "test ChromaDB: Question=山田さんの職業は何ですか。\n",
      "retrieved doc 0: id=doc1, distances=0.4490359425544739, metadata=None\n",
      "          text=果物屋の山田です。以前は八百屋でした。甘いものが好きです。下戸です。\n",
      "retrieved doc 1: id=doc4, distances=0.732514500617981, metadata=None\n",
      "          text=サイクリングの好きな鈴木さんは自転車で会社へ通勤しています。高橋さんは会社の同僚です。\n",
      "retrieved doc 2: id=doc2, distances=0.743468165397644, metadata=None\n",
      "          text=佐藤さんは酒屋を営んでいました。現在はコンビニの店長です。泣き上戸です。\n",
      "\n",
      "Q&A ----------------\n",
      "\n",
      "Q0: query=山田さんの職業は何ですか。,\n",
      "response=あら、山田さんは果物屋さんなんですね！前は八百屋さんだったんですか。甘いものが好きで、お酒は飲めないって、なんだか親近感湧きますね！\n",
      "\n",
      "retrieved doc 0: id=doc1, distances=0.4490359425544739, metadata=None\n",
      "          text=果物屋の山田です。以前は八百屋でした。甘いものが好きです。下戸です。\n",
      "retrieved doc 1: id=doc4, distances=0.732514500617981, metadata=None\n",
      "          text=サイクリングの好きな鈴木さんは自転車で会社へ通勤しています。高橋さんは会社の同僚です。\n",
      "retrieved doc 2: id=doc2, distances=0.743468165397644, metadata=None\n",
      "          text=佐藤さんは酒屋を営んでいました。現在はコンビニの店長です。泣き上戸です。\n",
      "\n",
      "Q1: query=佐藤さんの職業は何ですか。,\n",
      "response=あら、佐藤さんですか。昔は酒屋さんをやられてたみたいだけど、今はコンビニの店長さんなんですね！しかも泣き上戸だなんて、なんだか親近感がわきますね（笑）\n",
      "\n",
      "retrieved doc 0: id=doc2, distances=0.40844571590423584, metadata=None\n",
      "          text=佐藤さんは酒屋を営んでいました。現在はコンビニの店長です。泣き上戸です。\n",
      "retrieved doc 1: id=doc7, distances=0.5289136171340942, metadata=None\n",
      "          text=京都にお住いの小林さんは、佐藤さんのおいです。\n",
      "retrieved doc 2: id=doc3, distances=0.557520866394043, metadata=None\n",
      "          text=東京の渡辺さんと佐藤さんは、たまに居酒屋で一緒に飲んでいるようです。\n",
      "\n",
      "Q2: query=お酒を飲む人は誰ですか。,\n",
      "response=おやおや、誰がお酒を飲むかって？えーっとね、\n",
      "\n",
      "*   東京の渡辺さんと佐藤さんは、たまに一緒に飲んでるみたいだね。\n",
      "*   中村さんは、上司に飲みに誘われるけど、参加するかどうかは半々ってとこかな。\n",
      "\n",
      "山田さんは甘いもの好きで下戸みたいだから、飲まないみたいだね。\n",
      "\n",
      "retrieved doc 0: id=doc3, distances=0.6251603960990906, metadata=None\n",
      "          text=東京の渡辺さんと佐藤さんは、たまに居酒屋で一緒に飲んでいるようです。\n",
      "retrieved doc 1: id=doc1, distances=0.6808698773384094, metadata=None\n",
      "          text=果物屋の山田です。以前は八百屋でした。甘いものが好きです。下戸です。\n",
      "retrieved doc 2: id=doc6, distances=0.6953639984130859, metadata=None\n",
      "          text=中村さんは高橋さんの勤めている会社の上司です。よく飲みに誘われますが参加するかは半々です。\n",
      "\n",
      "Q3: query=関東に住んでいる人は誰ですか。,\n",
      "response=あら、それは面白い質問ね！えーっと、情報からすると…\n",
      "\n",
      "*   **渡辺さん** は東京に住んでるみたいね。\n",
      "*   **佐藤さん** も東京に住んでるわ。渡辺さんと飲み友達みたいだし。\n",
      "*   **小林さん** は京都にお住まいなのね。\n",
      "*   **加藤さん** に関しては、家族構成はわかるけど、どこに住んでるかは分からないわね。\n",
      "\n",
      "だから、確実に言えるのは **渡辺さんと佐藤さんが関東に住んでいる** ってことね！加藤さんも関東に住んでるといいわね。\n",
      "\n",
      "retrieved doc 0: id=doc3, distances=0.759975016117096, metadata=None\n",
      "          text=東京の渡辺さんと佐藤さんは、たまに居酒屋で一緒に飲んでいるようです。\n",
      "retrieved doc 1: id=doc7, distances=0.790023684501648, metadata=None\n",
      "          text=京都にお住いの小林さんは、佐藤さんのおいです。\n",
      "retrieved doc 2: id=doc8, distances=0.792526125907898, metadata=None\n",
      "          text=加藤さんは5人家族です。\n"
     ]
    }
   ],
   "source": [
    "# 検索対象テキスト\n",
    "texts = [\n",
    "    '石川です。エンジニアです。散歩は嫌いではありません。', \n",
    "    '果物屋の山田です。以前は八百屋でした。甘いものが好きです。下戸です。',\n",
    "    '佐藤さんは酒屋を営んでいました。現在はコンビニの店長です。泣き上戸です。',\n",
    "    '東京の渡辺さんと佐藤さんは、たまに居酒屋で一緒に飲んでいるようです。',\n",
    "    'サイクリングの好きな鈴木さんは自転車で会社へ通勤しています。高橋さんは会社の同僚です。',\n",
    "    '伊藤さんと山本さんは、よく一緒に奥多摩へキャンプに行くようです',\n",
    "    '中村さんは高橋さんの勤めている会社の上司です。よく飲みに誘われますが参加するかは半々です。',\n",
    "    '京都にお住いの小林さんは、佐藤さんのおいです。',\n",
    "    '加藤さんは5人家族です。',\n",
    "]\n",
    "\n",
    "# テキストをエンベディング化(vector化)する\n",
    "embeddings = embed_texts(texts)# => [[vec1], [vec2], ...]\n",
    "\n",
    "# 確認: テキストのエンベディング内容(先頭の2テキスト、enbeddingの先頭の5次元分)\n",
    "print(f\"len(embeddings)={len(embeddings)}\")\n",
    "for i, embedding in enumerate(embeddings[:2]):\n",
    "    print(f\"{i:2d} embedding First 5 values: {embedding[:5]}\")\n",
    "# -------------------------------------------\n",
    "\n",
    "# Document から必要な情報をまとめる\n",
    "ids = [f\"doc{i}\" for i in range(len(texts))] # id: ユニークな文字列\n",
    "\n",
    "# 確認\n",
    "print(f\"Confirm: len(ids)={len(ids)}, len(embeddings)={len(embeddings)}, len(texts)={len(texts)}\")\n",
    "\n",
    "# 一括で追加\n",
    "collection.add(\n",
    "    ids=ids,\n",
    "    embeddings=embeddings,\n",
    "    documents=texts,\n",
    "#    metadatas=metadatas        # (今回未使用、空辞書だとエラー)\n",
    ")\n",
    "print(f\"collection count={collection.count()}\")\n",
    "\n",
    "# 確認: DB検索 -------------------------------\n",
    "query = '山田さんの職業は何ですか。'\n",
    "results = collection.query(\n",
    "    query_embeddings=embed_texts(query), # queryのリスト(複数のqueryを投げられる)をベクトル化\n",
    "    n_results=3,                           # 上位の取得件数\n",
    "#    where={\"author\": \"夏目漱石\"}           # ★ metadata フィルタ(今回未使用)\n",
    ")\n",
    "retreaved_texts = results['documents'][0]\n",
    "\n",
    "print(f\"test ChromaDB: Question={query}\")\n",
    "for i in range(len(results['documents'][0])):     # [0]が必要なのは、複数のqueryを投げられるため\n",
    "    print(f\"retrieved doc {i}: id={results['ids'][0][i]}, \" +\n",
    "          f\"distances={results['distances'][0][i]}, metadata={results['metadatas'][0][i]}\" +\n",
    "          f\"\\n          text={results['documents'][0][i][:200]}\")   # 最初の200文字だけ表示\n",
    "# -------------------------------------------\n",
    "\n",
    "# LLMモデルを使用してレスポンスを生成\n",
    "queries = []\n",
    "queries.append('山田さんの職業は何ですか。')\n",
    "queries.append('佐藤さんの職業は何ですか。')\n",
    "queries.append('お酒を飲む人は誰ですか。')\n",
    "queries.append('関東に住んでいる人は誰ですか。')\n",
    "print(f\"\\nQ&A ----------------\")\n",
    "for q_no, query in enumerate(queries):\n",
    "    results = collection.query(\n",
    "        query_embeddings=embed_texts([query]),\n",
    "        n_results=3\n",
    "    )\n",
    "    retreaved_texts = results['documents'][0]\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model=llm_model,\n",
    "        contents=[f\"QUESTION{query}\", f\"CONTENTS\"] + retreaved_texts,\n",
    "        config=genai.types.GenerateContentConfig(\n",
    "            system_instruction=\"あなたは気さくな隣人です。質問に日常会話的に答えてください。\",\n",
    "            temperature=0.7,  # ★ creativity の度合いを調整\n",
    "        )\n",
    "    )\n",
    "    print(f\"\\nQ{q_no}: query={query},\\nresponse={response.text}\")\n",
    "    for i in range(len(results['documents'][0])):     # [0]が必要なのは、複数のqueryを投げられるため\n",
    "        print(f\"retrieved doc {i}: id={results['ids'][0][i]}, \" +\n",
    "              f\"distances={results['distances'][0][i]}, metadata={results['metadatas'][0][i]}\" +\n",
    "              f\"\\n          text={results['documents'][0][i][:200]}\")   # 最初の200文字だけ表示\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3cbc25-2bfa-4f31-afe9-2f4924a96b09",
   "metadata": {},
   "source": [
    "## 大きなドキュメントの分割、メタデータの活用(未完)\n",
    "\n",
    "ドキュメントとして、青空文庫を利用させていただきました。\n",
    "\n",
    "「Langchainを使わないで、」という条件は日和ってしまいました。\n",
    "\n",
    "以下の機能は単機能で、特にRecursiveCharacterTextSplitter()は代わりになるライブラリが見つからず、スクラッチで作成するのも結構大変ということで、使わせていただきます。\n",
    " - Documentクラス                    # テキスト+メタデータ  \n",
    " - DirectoryLoader()                 # ディレクトリ単位でファイルを取得、Document型へ  \n",
    " - RecursiveCharacterTextSplitter()  # Document型のテキストを指定サイズでChankへ分割  \n",
    "                                     # 区切文字列、ラップサイズを指定、メタデータを各Chankへコピー  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff2a6d-8abe-4a38-9084-28d4340571e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.genai as genai\n",
    "import chromadb\n",
    "from langchain.schema import Document\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# テキストファイル・メタデータ\n",
    "matadata_dic = {\n",
    "    '1_kumono_ito.txt': {\n",
    "        'genre': 'novel', 'title':'蜘蛛の糸',          'author':'芥川竜之介', 'year':'1918'},\n",
    "    '2_chumonno_oi_ryoriten.txt': {\n",
    "        'genre': 'novel', 'title':'注文の多い料理店',  'author':'宮沢賢治',   'year':'1924'},\n",
    "    '2_kazeno_matasaburo.txt': {\n",
    "        'genre': 'novel', 'title':'風の又三郎',        'author':'宮沢賢治',   'year':'1934'},\n",
    "    '2_serohikino_goshu.txt': {\n",
    "        'genre': 'novel', 'title':'セロ弾きのゴーシュ', 'author':'宮沢賢治',   'year':'1934'},\n",
    "    '2_gingatetsudono_yoru.txt': {\n",
    "        'genre': 'novel', 'title':'銀河鉄道の夜',      'author':'宮沢賢治',   'year':'1934'},\n",
    "    '3_bocchan.txt': {\n",
    "        'genre': 'novel', 'title':'坊ちゃん',         'author':'夏目漱石',   'year':'1906'},\n",
    "    '4_wagahaiwa_nekodearu.txt': {\n",
    "        'genre': 'novel', 'title':'吾輩は猫である',    'author':'夏目漱石',   'year':'1905'},\n",
    "    '4_kaijin_nijumenso.txt': {\n",
    "        'genre': 'novel', 'title':'怪人二十面相',      'author':'江戸川乱歩', 'year':'1936'},\n",
    "    '5_sanshodayu.txt': {\n",
    "        'genre': 'novel', 'title':'山椒大夫',         'author':'森鷗外',     'year':'1915'},\n",
    "}\n",
    "null_dic = {'genre':'','title':'', 'author':'','year':''}\n",
    "\n",
    "# 小説データをロード\n",
    "novels_dir = './novels/'\n",
    "loader = DirectoryLoader(novels_dir, glob='*.txt') # ディレクトリ内の.txtを指定して\n",
    "documents = loader.load()   # ドキュメント(メタデータ(ファイル名)+テキスト)としてロード\n",
    "\n",
    "# 各ドキュメントにメタデータを付与\n",
    "for doc in documents:\n",
    "    fn = os.path.basename(doc.metadata[\"source\"])\n",
    "    doc.metadata.update({'filename': fn} | matadata_dic.get(fn, null_dic))\n",
    "    print(doc.metadata) # 確認\n",
    "\n",
    "# ドキュメントをチャンクへ分割\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=10000,\n",
    "    chunk_overlap=100,\n",
    "    separators=['。', '\\n'] # 分割位置の指定\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
