{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1496b77-7e6b-4380-a968-0e3bf5b799c2",
   "metadata": {},
   "source": [
    "## Keyword Search (Sparse Vector Search)\n",
    "\n",
    "インストール\n",
    "```\n",
    "pip install \"transformers==4.45\" \"flagembedding==1.3.5\" \"tokenizers==0.20.3\"\n",
    "pip install qdrant-client # Sparse Vector DB\n",
    "pip install torch\n",
    "```\n",
    "\n",
    "### 利用ライブラリの解説\n",
    "\n",
    "| ライブラリ | 役割 | インストール |\n",
    "|---|---|---|\n",
    "| **FlagEmbedding** | BGE-M3のSparse/Denseエンコード（BAAI公式） | pip install FlagEmbedding |\n",
    "| **qdrant-client** | ベクトルDBクライアント。Sparseベクトルの永続化・検索 | pip install qdrant-client |\n",
    "| **torch** | FlagEmbeddingの依存ライブラリ | pip install torch |\n",
    "\n",
    "Qdrantはローカルフォルダに永続化できるため、サーバー不要でファイルベースのDBとして利用できます。\n",
    "\n",
    "### 開発元/ライセンス\n",
    "\n",
    "| | BGE-M3 | Qdrant |\n",
    "|---|---|---|\n",
    "| 開発元 | BAAI（中国・研究機関） | Qdrant GmbH（ドイツ・企業） |\n",
    "| ライセンス | MIT | Apache 2.0 |\n",
    "| 商用利用 | ✅ | ✅ |\n",
    "| 無償利用 | ✅ | ✅（セルフホスト） |\n",
    "\n",
    "<div style=\"text-align: center\">BGE-M3 https://huggingface.co/BAAI/bge-m3</div>  \n",
    "\n",
    "### 処理フロー概要\n",
    "\n",
    "#### インデックス作成\n",
    "```\n",
    "コーパス\n",
    " └─ BGE-M3エンコード → Sparseベクトル（{token_id: weight}）\n",
    "     |  Qdrant 初期化 <- ローカルに作成すれば、次回起動時もデータが残る\n",
    "     |  Qdrant コレクション作成\n",
    "     └─ Qdrant（ローカルディスク）にアップサート\n",
    "```\n",
    "ローカルに作成すれば、2回目以降の起動では **Step 2でDBを読み込み、Step 3はスキップ** されるため、エンコードとアップサートをやり直す必要がなくなります。\n",
    "\n",
    "#### クエリ\n",
    "```\n",
    "クエリ\n",
    " └─ BGE-M3エンコード → Sparseベクトル\n",
    "     └─ Qdrant検索 → スコア順で結果返却\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aee121b-c42d-47ce-b65d-e9ae85526ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.13.12 (tags/v3.13.12:1cbe481, Feb  3 2026, 18:22:25) [MSC v.1944 64 bit (AMD64)]\n",
      "transformers=4.45.0, flagembedding=1.3.5, tokenizers=0.20.3, qdrant_client=1.16.2, \n",
      "Step 0: BGE-M3モデルをロード中...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b43aaed0614600baa7a0ea990a84de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from importlib.metadata import version\n",
    "import numpy as np\n",
    "\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import (\n",
    "    SparseVectorParams,\n",
    "    SparseIndexParams,\n",
    "    PointStruct,\n",
    "    SparseVector,\n",
    "    NamedSparseVector,\n",
    ")\n",
    "print(sys.version)\n",
    "print(f\"transformers={version('transformers')}, flagembedding={version('flagembedding')}, \" +\n",
    "      f\"tokenizers={version('tokenizers')}, qdrant_client={version('qdrant-client')}, \")\n",
    "\n",
    "# ============================================================\n",
    "# 設定\n",
    "# ============================================================\n",
    "COLLECTION_NAME = \"notes\"              # Qdrantコレクション名\n",
    "PERSIST_DIR     = \"./qdrant_storage\"   # 永続化ディレクトリ（ローカルフォルダ）\n",
    "SPARSE_NAME     = \"bgem3_sparse\"       # Sparseベクトルのフィールド名\n",
    "\n",
    "# ============================================================\n",
    "# コーパス（インデックス対象のテキスト）\n",
    "# ============================================================\n",
    "corpus = [\n",
    "    '順に秤量し、ビーカーに加える。各秤量値は実験ノートに記録しておく。',\n",
    "    'スターラーで軽く攪拌して溶解・混合を促進する。',\n",
    "    '順番に加え、それぞれ秤量値を記録する。',\n",
    "    '同じビーカー内で再度スターラー攪拌を行う。',\n",
    "    'ビーカーを超音波分散機にセットし分散処理を行う。'\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# Step 0: BGE-M3モデルのロード\n",
    "#   - use_fp16=True: 半精度演算でメモリ・速度を最適化\n",
    "#   - CPUのみの環境では use_fp16=False に変更\n",
    "# ============================================================\n",
    "print(\"Step 0: BGE-M3モデルをロード中...\")\n",
    "model = BGEM3FlagModel(\"BAAI/bge-m3\", use_fp16=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd564f54-94b3-433d-87a5-a40aac886034",
   "metadata": {},
   "source": [
    "## Create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b213ab-bec0-4faa-950c-16c3417390ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Create index ###\n",
      "\n",
      "Step 1: コーパスをSparseエンコード中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|█████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 697.37it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Inference Embeddings: 100%|██████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- エンコード結果サンプル（doc[0]の上位5トークン）---\n",
      "  token: 秤                weight: 0.2553\n",
      "  token: 実験               weight: 0.2403\n",
      "  token: カー               weight: 0.2383\n",
      "  token: ノート              weight: 0.2167\n",
      "  token: 量                weight: 0.2130\n",
      "\n",
      "Step 2: Qdrantクライアントを初期化（インメモリで使用）\n",
      "Step 3: コレクション 'notes' を新規作成\n",
      "Step 4: ドキュメントをQdrantにアップサート中...\n",
      "  → 5 件のドキュメントを保存しました\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Create index\n",
    "print(\"\\n### Create index ###\\n\")\n",
    "# ============================================================\n",
    "# Step 1: BGE-M3でSparseエンコード\n",
    "#   - return_dense=False     : Denseベクトルは今回不要\n",
    "#   - return_sparse=True     : Sparseベクトルを取得\n",
    "#   - return_colbert_vecs=False : ColBERTも今回不要\n",
    "#   出力: lexical_weights = [{token_id(str): weight(float), ...}, ...]\n",
    "# ============================================================\n",
    "print(\"Step 1: コーパスをSparseエンコード中...\")\n",
    "encoded = model.encode(\n",
    "    corpus,               # リスト形式\n",
    "    return_dense=False,   # Denseベクトルは不要\n",
    "    return_sparse=True,   # Sparseベクトルのみ取得\n",
    "    return_colbert_vecs=False, # ColBERTベクトルは不使用\n",
    "    batch_size=4,\n",
    ")\n",
    "lexical_weights = encoded[\"lexical_weights\"]  # 各文書のSparseベクトル（辞書形式）\n",
    "\n",
    "# エンコード結果の確認（どのトークンに重みが付いたか）\n",
    "print(\"\\n--- エンコード結果サンプル（doc[0]の上位5トークン）---\")\n",
    "sample = sorted(lexical_weights[0].items(), key=lambda x: -x[1])[:5]\n",
    "for token_id, weight in sample:\n",
    "    # token_idからトークン文字列に変換して表示\n",
    "    token_str = model.tokenizer.convert_ids_to_tokens([int(token_id)])\n",
    "    print(f\"  token: {token_str[0]:15s}  weight: {weight:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Step 2: Qdrantクライアントの初期化（永続化モード/インメモリ）\n",
    "#   - path=PERSIST_DIR を指定するとローカルフォルダにDBを保存\n",
    "#   - 次回起動時も同じpathを指定すればデータが残っている\n",
    "#   （インメモリにする場合は QdrantClient(\":memory:\") に変更）\n",
    "# ============================================================\n",
    "#print(f\"\\nStep 2: Qdrantクライアントを初期化（永続化先: {PERSIST_DIR}）\")\n",
    "#client = QdrantClient(path=PERSIST_DIR)\n",
    "print(f\"\\nStep 2: Qdrantクライアントを初期化（インメモリで使用）\")\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "# ============================================================\n",
    "# Step 3: コレクションの作成（初回のみ）\n",
    "#   - 既に存在する場合はスキップ\n",
    "#   - SparseVectorParams: Sparseベクトル専用のフィールド設定\n",
    "#   - vectors_config={}: Denseベクトルは使用しないため空\n",
    "# ============================================================\n",
    "existing = [c.name for c in client.get_collections().collections]\n",
    "\n",
    "if COLLECTION_NAME not in existing:\n",
    "    print(f\"Step 3: コレクション '{COLLECTION_NAME}' を新規作成\")\n",
    "    client.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config={},          # Denseなし\n",
    "        sparse_vectors_config={\n",
    "            SPARSE_NAME: SparseVectorParams(\n",
    "                # インデックスもディスクに永続化、インメモリの場合は無視される\n",
    "                index=SparseIndexParams(on_disk=True)\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "else:\n",
    "    print(f\"Step 3: コレクション '{COLLECTION_NAME}' は既に存在 → スキップ\")\n",
    "\n",
    "# ============================================================\n",
    "# Step 4: ドキュメントをQdrantにアップサート（追加 or 更新）\n",
    "#   - PointStruct: Qdrantの1レコード単位\n",
    "#     - id      : ドキュメントID（整数）\n",
    "#     - vector  : Sparseベクトル（indices + values）\n",
    "#     - payload : 元テキスト等のメタデータ（検索結果で取得可能）\n",
    "#   - SparseVector: {indices: [token_id, ...], values: [weight, ...]}\n",
    "# ============================================================\n",
    "print(\"Step 4: ドキュメントをQdrantにアップサート中...\")\n",
    "points = []\n",
    "for idx, (text, lw) in enumerate(zip(corpus, lexical_weights)):\n",
    "    indices = [int(k)   for k in lw.keys()]\n",
    "    values  = [float(v) for v in lw.values()]\n",
    "    points.append(\n",
    "        PointStruct(\n",
    "            id=idx,\n",
    "            vector={\n",
    "                SPARSE_NAME: SparseVector(indices=indices, values=values)\n",
    "            },\n",
    "            payload={\"text\": text, \"doc_id\": idx}\n",
    "        )\n",
    "    )\n",
    "\n",
    "client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "print(f\"  → {len(points)} 件のドキュメントを保存しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cac48f-88b3-4cf3-90d4-68ed36a705e2",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c93039b-cedd-46c4-a8d2-7d4f8336449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Query ###\n",
      "\n",
      "\n",
      "Query Step 1: クエリをエンコード中... Query: '攪拌混合'\n",
      "  クエリの展開トークン（上位5件）:\n",
      "    攪拌               weight: 0.3216\n",
      "    混合               weight: 0.2939\n",
      "    ▁                weight: 0.0586\n",
      "\n",
      "Query Step 2: 検索実行中...\n",
      "\n",
      "=== 検索結果（Query: '攪拌混合'）===\n",
      "  [1位] score=0.1586 | スターラーで軽く攪拌して溶解・混合を促進する。\n",
      "  [2位] score=0.0922 | 同じビーカー内で再度スターラー攪拌を行う。\n",
      "  [3位] score=0.0013 | 順番に加え、それぞれ秤量値を記録する。\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Query\n",
    "print(\"\\n### Query ###\\n\")\n",
    "# ============================================================\n",
    "# Query Step 1: クエリのエンコード\n",
    "#   - コーパスと同じモデル・設定でエンコードする\n",
    "# ============================================================\n",
    "query = '攪拌混合'\n",
    "print(f\"\\nQuery Step 1: クエリをエンコード中... Query: '{query}'\")\n",
    "\n",
    "# BGE-M3でエンコード\n",
    "q_encoded = model.encode(\n",
    "    [query],              # リスト形式で渡す（バッチ処理のため）\n",
    "    return_dense=False,   # Denseベクトルは不要\n",
    "    return_sparse=True,   # Sparseベクトルのみ取得\n",
    "    return_colbert_vecs=False,\n",
    ")\n",
    "\n",
    "# lexical_weights（{token_id: weight}の辞書）を取得\n",
    "q_lw      = q_encoded[\"lexical_weights\"][0]\n",
    "q_indices = [int(k)   for k in q_lw.keys()]\n",
    "q_values  = [float(v) for v in q_lw.values()]\n",
    "\n",
    "print(\"  クエリの展開トークン（上位5件）:\")\n",
    "top_tokens = sorted(q_lw.items(), key=lambda x: -x[1])[:5]\n",
    "for token_id, weight in top_tokens:\n",
    "    token_str = model.tokenizer.convert_ids_to_tokens([int(token_id)])\n",
    "    print(f\"    {token_str[0]:15s}  weight: {weight:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Query Step 2: Sparseベクトル検索\n",
    "#   - NamedSparseVector: フィールド名 + SparseVectorを指定\n",
    "#   - limit: 上位何件を返すか\n",
    "#   - with_payload=True: テキスト等のメタデータも返す\n",
    "# ============================================================\n",
    "print(\"\\nQuery Step 2: 検索実行中...\")\n",
    "results = client.query_points(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query=SparseVector(indices=q_indices, values=q_values),\n",
    "    using=SPARSE_NAME,\n",
    "    limit=3,\n",
    "    with_payload=True,\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Query Step 3: 結果表示\n",
    "# ============================================================\n",
    "print(f\"\\n=== 検索結果（Query: '{query}'）===\")\n",
    "for rank, hit in enumerate(results.points, start=1):\n",
    "    # tupleの場合 hit[0] が ScoredPoint\n",
    "    point = hit[0] if isinstance(hit, tuple) else hit\n",
    "    print(f\"  [{rank}位] score={point.score:.4f} | {point.payload['text']}\")\n",
    "\n",
    "\n",
    "\n",
    "### 実行結果イメージ\n",
    "dmy = '''\n",
    "Step 1: BGE-M3モデルをロード中...\n",
    "Step 2: コーパスをSparseエンコード中...\n",
    "\n",
    "--- エンコード結果サンプル（doc[0]の上位5トークン）---\n",
    "  token: ビーカー         weight: 1.2341\n",
    "  token: 秤量            weight: 1.1823\n",
    "  token: 記録            weight: 0.9412\n",
    "  ...\n",
    "\n",
    "Step 3: Qdrantクライアントを初期化（永続化先: ./qdrant_storage）\n",
    "Step 4: コレクション 'lab_notes' を新規作成\n",
    "Step 5: ドキュメントをQdrantにアップサート中...\n",
    "  → 5 件のドキュメントを保存しました\n",
    "\n",
    "Step 6: クエリをエンコード中... Query: '攪拌混合'\n",
    "  クエリの展開トークン（上位5件）:\n",
    "    攪拌            weight: 1.8923\n",
    "    混合            weight: 1.7341\n",
    "    スターラー       weight: 0.8231  ← 語彙拡張\n",
    "    ...\n",
    "\n",
    "=== 検索結果（Query: '攪拌混合'）===\n",
    "  [1位] score=2.4821 | スターラーで軽く攪拌して溶解・混合を促進する。\n",
    "  [2位] score=1.8234 | 同じビーカー内で再度スターラー攪拌を行う。\n",
    "  [3位] score=0.3241 | 順に秤量し、ビーカーに加える。...\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
